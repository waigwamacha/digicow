{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD w/ Prior concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 56,200 | Val: 2,218\n",
      "[LGB 07d]  AUC=0.9559  LogLoss=0.0614  PR-AUC=0.2416  Naive-PR=0.0140\n",
      "[CAT 07d]  AUC=0.9427  LogLoss=0.0542  PR-AUC=0.2755\n",
      "[ENS 07d]  AUC=0.9566  LogLoss=0.0532  PR-AUC=0.2601\n",
      "\n",
      "[LGB 90d]  AUC=0.9321  LogLoss=0.0779  PR-AUC=0.1605  Naive-PR=0.0304\n",
      "[CAT 90d]  AUC=0.9518  LogLoss=0.0566  PR-AUC=0.3277\n",
      "[ENS 90d]  AUC=0.9532  LogLoss=0.0640  PR-AUC=0.2799\n",
      "\n",
      "[LGB 120d]  AUC=0.9084  LogLoss=0.0883  PR-AUC=0.0823  Naive-PR=0.0419\n",
      "[CAT 120d]  AUC=0.9167  LogLoss=0.0637  PR-AUC=0.2977\n",
      "[ENS 120d]  AUC=0.9364  LogLoss=0.0739  PR-AUC=0.2973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # OLD ---- adds prior to train\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.metrics import roc_auc_score, log_loss, average_precision_score\n",
    "# import lightgbm as lgb\n",
    "# from catboost import CatBoostClassifier\n",
    "# # import xgboost as xgb\n",
    "# import ast\n",
    "\n",
    "# # ── 1. Load ──────────────────────────────────────────────────────────────────\n",
    "# # train_df = pd.read_csv('Train.csv')\n",
    "# # test_df  = pd.read_csv('Test.csv')\n",
    "# train_df = pd.read_csv('/app/digicow/data/Train.csv')\n",
    "# prior_df = pd.read_csv('/app/digicow/data/Prior.csv')\n",
    "# test_df = pd.read_csv('/app/digicow/data/Test.csv')\n",
    "\n",
    "# # train_df = pd.concat([prior_df, train_df], ignore_index=True) # PRIOR\n",
    "\n",
    "# # raise SystemExit(\"Stopping here to check data.\")\n",
    "\n",
    "# # ── 2. Parse topics ──────────────────────────────────────────────────────────\n",
    "# def parse_topics(s):\n",
    "#     try:\n",
    "#         parsed = ast.literal_eval(s)\n",
    "#         if isinstance(parsed, list):\n",
    "#             flat = []\n",
    "#             for item in parsed:\n",
    "#                 if isinstance(item, list): flat.extend(item)\n",
    "#                 else: flat.append(item)\n",
    "#             return flat\n",
    "#     except:\n",
    "#         return []\n",
    "        \n",
    "# full_train = pd.concat([prior_df, train_df], ignore_index=True)\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# topics_train = pd.DataFrame(\n",
    "#     # mlb.fit_transform(train_df['topics_list'].apply(parse_topics)),\n",
    "#     # columns=mlb.classes_, index=train_df.index\n",
    "#     mlb.fit_transform(full_train['topics_list'].apply(parse_topics)),\n",
    "#     columns=mlb.classes_, index=full_train.index\n",
    "# )\n",
    "# topics_test = pd.DataFrame(\n",
    "#     mlb.transform(test_df['topics_list'].apply(parse_topics)),\n",
    "#     columns=mlb.classes_, index=test_df.index\n",
    "# )\n",
    "# # train_df = pd.concat([train_df, topics_train], axis=1).drop(columns=['topics_list'])\n",
    "# full_train = pd.concat([full_train, topics_train], axis=1).drop(columns=['topics_list'])\n",
    "# test_df  = pd.concat([test_df,  topics_test],  axis=1).drop(columns=['topics_list'])\n",
    "\n",
    "# # raise SystemExit(\"Stopping here to check data.\")\n",
    "\n",
    "# # # ── 3. Temporal split ────────────────────────────────────────────────────────\n",
    "# # train_df['dt'] = pd.to_datetime(train_df['training_day'])\n",
    "# # test_df['dt']  = pd.to_datetime(test_df['training_day'])\n",
    "# # cutoff = pd.Timestamp('2025-03-01')\n",
    "\n",
    "# # df_tr  = train_df[train_df['dt'] < cutoff].copy()\n",
    "# # df_val = train_df[train_df['dt'] >= cutoff].copy()\n",
    "# # print(f\"Train: {len(df_tr):,} | Val: {len(df_val):,}\")\n",
    "\n",
    "# # ── 3. Temporal split ────────────────────────────────────────────────────────\n",
    "# # train_df['dt'] = pd.to_datetime(train_df['training_day'])\n",
    "# full_train['dt'] = pd.to_datetime(full_train['training_day'])\n",
    "# test_df['dt']  = pd.to_datetime(test_df['training_day'])\n",
    "# # prior_df['dt'] = pd.to_datetime(prior_df['training_day'])\n",
    "\n",
    "# prior_encoded = full_train.iloc[:len(prior_df)].copy()\n",
    "# train_encoded = full_train.iloc[len(prior_df):].copy()\n",
    "\n",
    "# # cutoff = pd.Timestamp('2025-03-01')\n",
    "# # df_val = train_df[train_df['dt'] >= cutoff].copy()\n",
    "# # df_tr  = pd.concat([prior_df, train_df[train_df['dt'] < cutoff]], ignore_index=True)\n",
    "# # print(f\"Train: {len(df_tr):,} | Val: {len(df_val):,}\")\n",
    "\n",
    "# cutoff = pd.Timestamp('2025-01-01')\n",
    "# df_val = train_encoded[train_encoded['dt'] >= cutoff].copy()\n",
    "# df_tr  = pd.concat([prior_encoded, train_encoded[train_encoded['dt'] < cutoff]], ignore_index=True)\n",
    "# print(f\"Train: {len(df_tr):,} | Val: {len(df_val):,}\")\n",
    "\n",
    "# # # ── 3b. Target encoding (computed from df_tr only, no leakage) ────────────\n",
    "# # targets = ['07', '90', '120']\n",
    "# # te_cols = []\n",
    "# # for days in targets:\n",
    "# #     col = f'adopted_within_{days}_days'\n",
    "# #     for grp in ['trainer', 'county', 'subcounty', 'ward']:\n",
    "# #         rate_map    = df_tr.groupby(grp)[col].mean()\n",
    "# #         global_mean = df_tr[col].mean()\n",
    "# #         col_name    = f'{grp}_adopt_{days}d'\n",
    "# #         df_tr[col_name]   = df_tr[grp].map(rate_map).fillna(global_mean)\n",
    "# #         df_val[col_name]  = df_val[grp].map(rate_map).fillna(global_mean)\n",
    "# #         test_df[col_name] = test_df[grp].map(rate_map).fillna(global_mean)\n",
    "# #         te_cols.append(col_name)\n",
    "\n",
    "# # raise SystemExit(\"Stopping here to check data.\")\n",
    "# # ── 4. Features ──────────────────────────────────────────────────────────────\n",
    "# cat_cols     = ['gender', 'registration', 'age', 'trainer', 'county', 'subcounty', 'ward']\n",
    "# topic_cols   = list(mlb.classes_)\n",
    "# numeric_cols = ['belong_to_cooperative', 'has_topic_trained_on'] + topic_cols #+ te_cols\n",
    "# feature_cols = cat_cols + numeric_cols\n",
    "\n",
    "# # LightGBM needs categoricals as 'category' dtype\n",
    "# def prep_lgb(df):\n",
    "#     X = df[feature_cols].copy()\n",
    "#     for c in cat_cols:\n",
    "#         X[c] = X[c].astype('category')\n",
    "#     return X\n",
    "\n",
    "# X_tr_lgb   = prep_lgb(df_tr)\n",
    "# X_val_lgb  = prep_lgb(df_val)\n",
    "# X_test_lgb = prep_lgb(test_df)\n",
    "\n",
    "# # CatBoost takes raw strings — no encoding needed\n",
    "# X_tr_cat   = df_tr[feature_cols].fillna('missing')\n",
    "# X_val_cat  = df_val[feature_cols].fillna('missing')\n",
    "# X_test_cat = test_df[feature_cols].fillna('missing')\n",
    "\n",
    "# cat_feature_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "\n",
    "# targets = ['07', '90', '120']\n",
    "# lgb_preds  = {}\n",
    "# cat_preds  = {}\n",
    "# # xgb_preds = {}\n",
    "# ens_preds  = {}\n",
    "\n",
    "# # ── 5. Train per target ──────────────────────────────────────────────────────\n",
    "# for days in targets:\n",
    "#     col = f'adopted_within_{days}_days'\n",
    "#     y_tr  = df_tr[col].values\n",
    "#     y_val = df_val[col].values\n",
    "\n",
    "#     prevalence = y_tr.mean()\n",
    "#     scale_pos  = (1 - prevalence) / prevalence  # for imbalance\n",
    "\n",
    "#     # ── LightGBM ──\n",
    "#     lgb_tr  = lgb.Dataset(X_tr_lgb,  label=y_tr)\n",
    "#     lgb_val = lgb.Dataset(X_val_lgb, label=y_val, reference=lgb_tr)\n",
    "\n",
    "#     params = {\n",
    "#         'objective':        'binary',\n",
    "#         'metric':           ['binary_logloss', 'auc'],\n",
    "#         'scale_pos_weight': scale_pos,\n",
    "#         'learning_rate':    0.05,\n",
    "#         'num_leaves':       31,\n",
    "#         'min_child_samples': 20,\n",
    "#         'feature_fraction': 0.8,\n",
    "#         'bagging_fraction': 0.8,\n",
    "#         'bagging_freq':     5,\n",
    "#         'verbose':          -1,\n",
    "#         'seed':             42,\n",
    "#     }\n",
    "#     lgb_model = lgb.train(\n",
    "#         params,\n",
    "#         lgb_tr,\n",
    "#         num_boost_round=500,\n",
    "#         valid_sets=[lgb_val],\n",
    "#         callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)]\n",
    "#     )\n",
    "#     lgb_val_prob  = lgb_model.predict(X_val_lgb)\n",
    "#     lgb_test_prob = lgb_model.predict(X_test_lgb)\n",
    "#     lgb_preds[days] = lgb_test_prob\n",
    "\n",
    "#     auc   = roc_auc_score(y_val, lgb_val_prob)\n",
    "#     ll    = log_loss(y_val, lgb_val_prob)\n",
    "#     prauc = average_precision_score(y_val, lgb_val_prob)\n",
    "#     print(f\"[LGB {days}d]  AUC={auc:.4f}  LogLoss={ll:.4f}  PR-AUC={prauc:.4f}  Naive-PR={prevalence:.4f}\")\n",
    "\n",
    "#     # ── CatBoost ──\n",
    "#     cat_model = CatBoostClassifier(\n",
    "#         iterations=1000,\n",
    "#         learning_rate=0.03,\n",
    "#         depth=6,\n",
    "#         loss_function='Logloss',\n",
    "#         eval_metric='Logloss',  # optimise for LogLoss (75% of score)\n",
    "#         l2_leaf_reg=5,\n",
    "#         cat_features=cat_feature_indices,\n",
    "#         early_stopping_rounds=50,\n",
    "#         random_seed=42,\n",
    "#         verbose=0,\n",
    "#     )\n",
    "#     cat_model.fit(\n",
    "#         X_tr_cat, y_tr,\n",
    "#         eval_set=(X_val_cat, y_val),\n",
    "#     )\n",
    "#     cat_val_prob  = cat_model.predict_proba(X_val_cat)[:, 1]\n",
    "#     cat_test_prob = cat_model.predict_proba(X_test_cat)[:, 1]\n",
    "#     cat_preds[days] = cat_test_prob\n",
    "\n",
    "#     auc   = roc_auc_score(y_val, cat_val_prob)\n",
    "#     ll    = log_loss(y_val, cat_val_prob)\n",
    "#     prauc = average_precision_score(y_val, cat_val_prob)\n",
    "#     print(f\"[CAT {days}d]  AUC={auc:.4f}  LogLoss={ll:.4f}  PR-AUC={prauc:.4f}\")\n",
    "\n",
    "#     # # ── XGBoost ──\n",
    "#     # xgb_tr  = xgb.DMatrix(X_tr_lgb,  label=y_tr,  enable_categorical=True)\n",
    "#     # xgb_val = xgb.DMatrix(X_val_lgb, label=y_val, enable_categorical=True)\n",
    "#     # xgb_test = xgb.DMatrix(X_test_lgb,             enable_categorical=True)\n",
    "\n",
    "#     # xgb_params = {\n",
    "#     #     'objective':        'binary:logistic',\n",
    "#     #     'eval_metric':      ['logloss', 'auc'],\n",
    "#     #     'scale_pos_weight': scale_pos,\n",
    "#     #     'learning_rate':    0.05,\n",
    "#     #     'max_depth':        4,\n",
    "#     #     'subsample':        0.8,\n",
    "#     #     'colsample_bytree': 0.8,\n",
    "#     #     'min_child_weight': 20,\n",
    "#     #     'tree_method':      'hist',\n",
    "#     #     'device':           'cpu',\n",
    "#     #     'seed':             42,\n",
    "#     # }\n",
    "#     # xgb_model = xgb.train(\n",
    "#     #     xgb_params,\n",
    "#     #     xgb_tr,\n",
    "#     #     num_boost_round=500,\n",
    "#     #     evals=[(xgb_val, 'val')],\n",
    "#     #     early_stopping_rounds=50,\n",
    "#     #     verbose_eval=False,\n",
    "#     # )\n",
    "#     # xgb_val_prob  = xgb_model.predict(xgb_val)\n",
    "#     # xgb_test_prob = xgb_model.predict(xgb_test)\n",
    "#     # xgb_preds[days] = xgb_test_prob\n",
    "\n",
    "#     # auc   = roc_auc_score(y_val, xgb_val_prob)\n",
    "#     # ll    = log_loss(y_val, xgb_val_prob)\n",
    "#     # prauc = average_precision_score(y_val, xgb_val_prob)\n",
    "#     # print(f\"[XGB {days}d]  AUC={auc:.4f}  LogLoss={ll:.4f}  PR-AUC={prauc:.4f}\")\n",
    "\n",
    "\n",
    "    \n",
    "#     # ── Ensemble (simple average) ──\n",
    "#     ens_val_prob  = (lgb_val_prob + cat_val_prob) / 2\n",
    "#     ens_test_prob = (lgb_test_prob + cat_test_prob) / 2\n",
    "#     ens_preds[days] = ens_test_prob\n",
    "\n",
    "#     auc   = roc_auc_score(y_val, ens_val_prob)\n",
    "#     ll    = log_loss(y_val, ens_val_prob)\n",
    "#     prauc = average_precision_score(y_val, ens_val_prob)\n",
    "#     print(f\"[ENS {days}d]  AUC={auc:.4f}  LogLoss={ll:.4f}  PR-AUC={prauc:.4f}\")\n",
    "#     print()\n",
    "\n",
    "#     # # ── Ensemble (3-way average) ──\n",
    "#     # ens_val_prob  = (lgb_val_prob + cat_val_prob + xgb_val_prob) / 3\n",
    "#     # ens_test_prob = (lgb_test_prob + cat_test_prob + xgb_test_prob) / 3\n",
    "#     # ens_preds[days] = ens_test_prob\n",
    "\n",
    "#     # auc   = roc_auc_score(y_val, ens_val_prob)\n",
    "#     # ll    = log_loss(y_val, ens_val_prob)\n",
    "#     # prauc = average_precision_score(y_val, ens_val_prob)\n",
    "#     # print(f\"[ENS {days}d]  AUC={auc:.4f}  LogLoss={ll:.4f}  PR-AUC={prauc:.4f}\")\n",
    "#     # print()\n",
    "\n",
    "# # # ── 6. Submission ────────────────────────────────────────────────────────────\n",
    "# # ss = pd.read_csv('SampleSubmission.csv')[['ID']]\n",
    "# # for days in targets:\n",
    "# #     ss[f'Target_{days}_AUC']     = ens_preds[days]\n",
    "# #     ss[f'Target_{days}_LogLoss'] = ens_preds[days]\n",
    "\n",
    "# # col_order = ['ID',\n",
    "# #              'Target_07_AUC', 'Target_90_AUC', 'Target_120_AUC',\n",
    "# #              'Target_07_LogLoss', 'Target_90_LogLoss', 'Target_120_LogLoss']\n",
    "# # ss[col_order].to_csv('submission_ensemble.csv', index=False)\n",
    "# # print(\"Saved submission_ensemble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 57,180 | Val: 1,238\n",
      "\n",
      "── Tuning 07d ──\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 0.0494307: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it]\n",
      "Best trial: 15. Best value: 0.0343982: 100%|██████████| 30/30 [24:52<00:00, 49.73s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT weight: 1.000\n",
      "\n",
      "── Tuning 90d ──\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.0669467: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n",
      "Best trial: 8. Best value: 0.0381926: 100%|██████████| 30/30 [16:17<00:00, 32.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT weight: 1.000\n",
      "\n",
      "── Tuning 120d ──\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.041528: 100%|██████████| 50/50 [01:59<00:00,  2.39s/it] \n",
      "Best trial: 28. Best value: 0.0440553: 100%|██████████| 30/30 [14:17<00:00, 28.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT weight: 0.389\n",
      "Saved best_params_concat.json\n",
      "[LGB 07d]  AUC=0.9761  LogLoss=0.0494\n",
      "[CAT 07d]  AUC=0.9844  LogLoss=0.0344\n",
      "[ENS 07d]  AUC=0.9844  LogLoss=0.0344\n",
      "\n",
      "[LGB 90d]  AUC=0.9706  LogLoss=0.0669\n",
      "[CAT 90d]  AUC=0.9784  LogLoss=0.0382\n",
      "[ENS 90d]  AUC=0.9784  LogLoss=0.0382\n",
      "\n",
      "[LGB 120d]  AUC=0.9726  LogLoss=0.0816\n",
      "[CAT 120d]  AUC=0.9661  LogLoss=0.0441\n",
      "[ENS 120d]  AUC=0.9763  LogLoss=0.0622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, log_loss, average_precision_score\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "import ast\n",
    "import json\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ── 1. Load ───────────────────────────────────────────────────────────────────\n",
    "train_df = pd.read_csv('/app/digicow/data/Train.csv')\n",
    "prior_df = pd.read_csv('/app/digicow/data/Prior.csv')\n",
    "test_df  = pd.read_csv('/app/digicow/data/Test.csv')\n",
    "\n",
    "# ── 2. Parse topics ───────────────────────────────────────────────────────────\n",
    "def parse_topics(s):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(s)\n",
    "        if isinstance(parsed, list):\n",
    "            flat = []\n",
    "            for item in parsed:\n",
    "                if isinstance(item, list): flat.extend(item)\n",
    "                else: flat.append(item)\n",
    "            return flat\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "full_train = pd.concat([prior_df, train_df], ignore_index=True)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "topics_train = pd.DataFrame(\n",
    "    mlb.fit_transform(full_train['topics_list'].apply(parse_topics)),\n",
    "    columns=mlb.classes_, index=full_train.index\n",
    ")\n",
    "topics_test = pd.DataFrame(\n",
    "    mlb.transform(test_df['topics_list'].apply(parse_topics)),\n",
    "    columns=mlb.classes_, index=test_df.index\n",
    ")\n",
    "full_train = pd.concat([full_train, topics_train], axis=1).drop(columns=['topics_list'])\n",
    "test_df    = pd.concat([test_df, topics_test],     axis=1).drop(columns=['topics_list'])\n",
    "\n",
    "# ── 3. Temporal split ─────────────────────────────────────────────────────────\n",
    "full_train['dt'] = pd.to_datetime(full_train['training_day'])\n",
    "test_df['dt']    = pd.to_datetime(test_df['training_day'])\n",
    "\n",
    "prior_encoded = full_train.iloc[:len(prior_df)].copy()\n",
    "train_encoded = full_train.iloc[len(prior_df):].copy()\n",
    "\n",
    "cutoff = pd.Timestamp('2025-03-01')\n",
    "df_val = train_encoded[train_encoded['dt'] >= cutoff].copy()\n",
    "df_tr  = pd.concat([prior_encoded, train_encoded[train_encoded['dt'] < cutoff]], ignore_index=True)\n",
    "print(f\"Train: {len(df_tr):,} | Val: {len(df_val):,}\")\n",
    "\n",
    "# ── 4. Features ───────────────────────────────────────────────────────────────\n",
    "cat_cols     = ['gender', 'registration', 'age', 'trainer', 'county', 'subcounty', 'ward']\n",
    "topic_cols   = list(mlb.classes_)\n",
    "numeric_cols = ['belong_to_cooperative', 'has_topic_trained_on'] + topic_cols\n",
    "feature_cols = cat_cols + numeric_cols\n",
    "\n",
    "def prep_lgb(df):\n",
    "    X = df[feature_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].astype('category')\n",
    "    return X\n",
    "\n",
    "X_tr_lgb   = prep_lgb(df_tr)\n",
    "X_val_lgb  = prep_lgb(df_val)\n",
    "X_test_lgb = prep_lgb(test_df)\n",
    "\n",
    "X_tr_cat   = df_tr[feature_cols].fillna('missing')\n",
    "X_val_cat  = df_val[feature_cols].fillna('missing')\n",
    "X_test_cat = test_df[feature_cols].fillna('missing')\n",
    "\n",
    "cat_feature_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "targets = ['07', '90', '120']\n",
    "\n",
    "# ── 5. Optuna tuning ──────────────────────────────────────────────────────────\n",
    "def tune_lgb(X_tr, y_tr, X_val, y_val, scale_pos):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective':         'binary',\n",
    "            'metric':            'binary_logloss',\n",
    "            'scale_pos_weight':  scale_pos,\n",
    "            'verbose':           -1,\n",
    "            'seed':              42,\n",
    "            'learning_rate':     trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'num_leaves':        trial.suggest_int('num_leaves', 16, 128),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "            'feature_fraction':  trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "            'bagging_fraction':  trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "            'bagging_freq':      trial.suggest_int('bagging_freq', 1, 10),\n",
    "            'reg_alpha':         trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True),\n",
    "            'reg_lambda':        trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True),\n",
    "        }\n",
    "        ds_tr  = lgb.Dataset(X_tr, label=y_tr)\n",
    "        ds_val = lgb.Dataset(X_val, label=y_val, reference=ds_tr)\n",
    "        model = lgb.train(\n",
    "            params, ds_tr,\n",
    "            num_boost_round=500,\n",
    "            valid_sets=[ds_val],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        return log_loss(y_val, model.predict(X_val))\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_cat(X_tr, y_tr, X_val, y_val, cat_feature_indices):\n",
    "    def objective(trial):\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=1000, random_seed=42, verbose=0,\n",
    "            cat_features=cat_feature_indices,\n",
    "            early_stopping_rounds=50,\n",
    "            loss_function='Logloss', eval_metric='Logloss',\n",
    "            learning_rate=      trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            depth=              trial.suggest_int('depth', 4, 8),\n",
    "            l2_leaf_reg=        trial.suggest_float('l2_leaf_reg', 1.0, 20.0),\n",
    "            bagging_temperature=trial.suggest_float('bagging_temperature', 0.0, 2.0),\n",
    "            random_strength=    trial.suggest_float('random_strength', 0.0, 2.0),\n",
    "            border_count=       trial.suggest_int('border_count', 32, 255),\n",
    "        )\n",
    "        model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "        return log_loss(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_weight(cat_prob, lgb_prob, y_true):\n",
    "    def objective(trial):\n",
    "        w = trial.suggest_float('cat_weight', 0.0, 1.0)\n",
    "        return log_loss(y_true, w * cat_prob + (1-w) * lgb_prob)\n",
    "    study = optuna.create_study(direction='minimize',\n",
    "        sampler=optuna.samplers.TPESampler(n_startup_trials=20, seed=42))\n",
    "    study.optimize(objective, n_trials=100)\n",
    "    return study.best_params['cat_weight']\n",
    "\n",
    "best_params  = {}\n",
    "best_weights = {}\n",
    "\n",
    "for days in targets:\n",
    "    col = f'adopted_within_{days}_days'\n",
    "    y_tr  = df_tr[col].values\n",
    "    y_val = df_val[col].values\n",
    "    prevalence = y_tr.mean()\n",
    "    scale_pos  = (1 - prevalence) / prevalence\n",
    "\n",
    "    print(f\"\\n── Tuning {days}d ──\")\n",
    "    lgb_best = tune_lgb(X_tr_lgb, y_tr, X_val_lgb, y_val, scale_pos)\n",
    "    cat_best = tune_cat(X_tr_cat, y_tr, X_val_cat, y_val, cat_feature_indices)\n",
    "    best_params[days] = {'lgb': lgb_best, 'cat': cat_best}\n",
    "\n",
    "    # retrain to get val probs for weight tuning\n",
    "    ds_tr  = lgb.Dataset(X_tr_lgb, label=y_tr)\n",
    "    ds_val = lgb.Dataset(X_val_lgb, label=y_val, reference=ds_tr)\n",
    "    lgb_m  = lgb.train({'objective':'binary','metric':'binary_logloss',\n",
    "                         'scale_pos_weight':scale_pos,'verbose':-1,'seed':42,**lgb_best},\n",
    "                        ds_tr, num_boost_round=500, valid_sets=[ds_val],\n",
    "                        callbacks=[lgb.early_stopping(50,verbose=False),lgb.log_evaluation(0)])\n",
    "    cat_m  = CatBoostClassifier(iterations=1000, loss_function='Logloss',\n",
    "                                 cat_features=cat_feature_indices, early_stopping_rounds=50,\n",
    "                                 random_seed=42, verbose=0, **cat_best)\n",
    "    cat_m.fit(X_tr_cat, y_tr, eval_set=(X_val_cat, y_val))\n",
    "\n",
    "    best_weights[days] = optimize_weight(cat_m.predict_proba(X_val_cat)[:,1],\n",
    "                                          lgb_m.predict(X_val_lgb), y_val)\n",
    "    print(f\"CAT weight: {best_weights[days]:.3f}\")\n",
    "\n",
    "# Save\n",
    "with open('/app/digicow/best_params_concat.json', 'w') as f:\n",
    "    json.dump({'params': best_params, 'weights': best_weights}, f, indent=2)\n",
    "print(\"Saved best_params_concat.json\")\n",
    "\n",
    "# Load\n",
    "with open('/app/digicow/best_params_concat.json') as f:\n",
    "    saved = json.load(f)\n",
    "best_params  = saved['params']\n",
    "best_weights = saved['weights']\n",
    "\n",
    "# ── 6. Train with tuned params ────────────────────────────────────────────────\n",
    "lgb_preds = {}\n",
    "cat_preds = {}\n",
    "ens_preds = {}\n",
    "\n",
    "for days in targets:\n",
    "    col = f'adopted_within_{days}_days'\n",
    "    y_tr  = df_tr[col].values\n",
    "    y_val = df_val[col].values\n",
    "    prevalence = y_tr.mean()\n",
    "    scale_pos  = (1 - prevalence) / prevalence\n",
    "\n",
    "    # ── LightGBM ──\n",
    "    lgb_tr     = lgb.Dataset(X_tr_lgb, label=y_tr)\n",
    "    lgb_val_ds = lgb.Dataset(X_val_lgb, label=y_val, reference=lgb_tr)\n",
    "    params = {\n",
    "        'objective': 'binary', 'metric': ['binary_logloss', 'auc'],\n",
    "        'scale_pos_weight': scale_pos, 'verbose': -1, 'seed': 42,\n",
    "        **best_params[days]['lgb']\n",
    "    }\n",
    "    lgb_model = lgb.train(\n",
    "        params, lgb_tr,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[lgb_val_ds],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    lgb_val_prob  = lgb_model.predict(X_val_lgb)\n",
    "    lgb_test_prob = lgb_model.predict(X_test_lgb)\n",
    "    lgb_preds[days] = lgb_test_prob\n",
    "    print(f\"[LGB {days}d]  AUC={roc_auc_score(y_val, lgb_val_prob):.4f}  LogLoss={log_loss(y_val, lgb_val_prob):.4f}\")\n",
    "\n",
    "    # ── CatBoost ──\n",
    "    cat_model = CatBoostClassifier(\n",
    "        iterations=1000, loss_function='Logloss', eval_metric='Logloss',\n",
    "        cat_features=cat_feature_indices, early_stopping_rounds=50,\n",
    "        random_seed=42, verbose=0,\n",
    "        **best_params[days]['cat']\n",
    "    )\n",
    "    cat_model.fit(X_tr_cat, y_tr, eval_set=(X_val_cat, y_val))\n",
    "    cat_val_prob  = cat_model.predict_proba(X_val_cat)[:, 1]\n",
    "    cat_test_prob = cat_model.predict_proba(X_test_cat)[:, 1]\n",
    "    cat_preds[days] = cat_test_prob\n",
    "    print(f\"[CAT {days}d]  AUC={roc_auc_score(y_val, cat_val_prob):.4f}  LogLoss={log_loss(y_val, cat_val_prob):.4f}\")\n",
    "\n",
    "    # ── Ensemble ──\n",
    "    # ens_val_prob  = (lgb_val_prob + cat_val_prob) / 2\n",
    "    # ens_test_prob = (lgb_test_prob + cat_test_prob) / 2\n",
    "    w = best_weights[days]\n",
    "    ens_val_prob  = w * cat_val_prob  + (1-w) * lgb_val_prob\n",
    "    ens_test_prob = w * cat_test_prob + (1-w) * lgb_test_prob\n",
    "    ens_preds[days] = ens_test_prob\n",
    "    print(f\"[ENS {days}d]  AUC={roc_auc_score(y_val, ens_val_prob):.4f}  LogLoss={log_loss(y_val, ens_val_prob):.4f}\\n\")\n",
    "\n",
    "# # ── 7. Submission ─────────────────────────────────────────────────────────────\n",
    "# ss = pd.read_csv('/app/digicow/data/SampleSubmission.csv')[['ID']]\n",
    "# for days in targets:\n",
    "#     ss[f'Target_{days}_AUC']     = ens_preds[days]\n",
    "#     ss[f'Target_{days}_LogLoss'] = ens_preds[days]\n",
    "\n",
    "# col_order = ['ID',\n",
    "#              'Target_07_AUC', 'Target_90_AUC', 'Target_120_AUC',\n",
    "#              'Target_07_LogLoss', 'Target_90_LogLoss', 'Target_120_LogLoss']\n",
    "# ss[col_order].to_csv('/app/digicow/submission_tuned.csv', index=False)\n",
    "# print(\"Saved submission_tuned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv — 5621 rows\n",
      "          ID  Target_07_AUC  Target_90_AUC  Target_120_AUC  Target_07_LogLoss  \\\n",
      "0  ID_LEG1GM       0.000646       0.004792        0.094164           0.000646   \n",
      "1  ID_1UKOKW       0.000265       0.000858        0.012638           0.000265   \n",
      "2  ID_U5H2YK       0.299165       0.153741        0.248571           0.299165   \n",
      "\n",
      "   Target_90_LogLoss  Target_120_LogLoss  \n",
      "0           0.004792            0.094164  \n",
      "1           0.000858            0.012638  \n",
      "2           0.153741            0.248571  \n"
     ]
    }
   ],
   "source": [
    "# ── Submission ────────────────────────────────────────────────────────────────\n",
    "ss = pd.read_csv('/app/digicow/data/SampleSubmission.csv')[['ID']]\n",
    "\n",
    "for days in targets:\n",
    "    ss[f'Target_{days}_AUC']     = ens_preds[days]\n",
    "    ss[f'Target_{days}_LogLoss'] = ens_preds[days]\n",
    "\n",
    "col_order = ['ID',\n",
    "             'Target_07_AUC', 'Target_90_AUC', 'Target_120_AUC',\n",
    "             'Target_07_LogLoss', 'Target_90_LogLoss', 'Target_120_LogLoss']\n",
    "\n",
    "ss = ss[col_order]\n",
    "ss.to_csv('/app/digicow/submission.csv', index=False)\n",
    "print(f\"Saved submission.csv — {ss.shape[0]} rows\")\n",
    "print(ss.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
